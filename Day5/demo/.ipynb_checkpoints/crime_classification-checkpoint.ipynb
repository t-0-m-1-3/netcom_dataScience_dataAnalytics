{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                     __Crime Classification Model using Pyspark__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "inputHidden": true
   },
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "# Image('spark_ml.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. __Scope__\n",
    "* We are interesting in a system that could classify crime discription into different categories. We want to create a system that could automatically assign a described crime to category which could  help law enforcements to assign right officers to crime or could automatically assign officers to crime based on the classification.  \n",
    "* We are using dataset from Kaggle on San Francisco Crime. Our responsibilty is to train a model based on 39 pre-defined categories, test the model accuracy and  deploy it into production. Given a new crime description, the system should assign it to one of 39 categories.\n",
    "\n",
    "* To solve this problem, we will use a variety of feature extraction techniques along with different supervised machine learning algorithms in Pyspark. \n",
    "\n",
    "* This is multi-class text classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __2. Setup Spark and load other libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "spark = pyspark.sql.SparkSession.builder.appName(\"clipper-pyspark\").getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "np.random.seed(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __3. Data Extraction__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Structure\n",
      "----------------------------------\n",
      "root\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      "\n",
      "None\n",
      " \n",
      "Dataframe preview\n",
      "+--------------+--------------------+\n",
      "|      Category|         Description|\n",
      "+--------------+--------------------+\n",
      "|      warrants|      warrant arrest|\n",
      "|other offenses|traffic violation...|\n",
      "|other offenses|traffic violation...|\n",
      "| larceny/theft|grand theft from ...|\n",
      "| larceny/theft|grand theft from ...|\n",
      "+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      " \n",
      "----------------------------------\n",
      "Total number of rows 878049\n"
     ]
    }
   ],
   "source": [
    "#Read the data into spark datafrome\n",
    "from pyspark.sql.functions import col, lower\n",
    "df = spark.read.format('csv')\\\n",
    "          .option('header','true')\\\n",
    "          .option('inferSchema', 'true')\\\n",
    "          .option('timestamp', 'true')\\\n",
    "          .load('train.csv')\n",
    "\n",
    "data = df.select(lower(col('Category')),lower(col('Descript')))\\\n",
    "        .withColumnRenamed('lower(Category)','Category')\\\n",
    "        .withColumnRenamed('lower(Descript)', 'Description')\n",
    "data.cache()\n",
    "print('Dataframe Structure')\n",
    "print('----------------------------------')\n",
    "print(data.printSchema())\n",
    "print(' ')\n",
    "print('Dataframe preview')\n",
    "print(data.show(5))\n",
    "print(' ')\n",
    "print('----------------------------------')\n",
    "print('Total number of rows', df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: __To familiar ourselves with the dataset, we need to see the top list of the crime categories and descriptions__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique value of Category: 39\n",
      " \n",
      "Top 10 Crime Category\n",
      "+--------------+----------+\n",
      "|      Category|totalValue|\n",
      "+--------------+----------+\n",
      "| larceny/theft|    174900|\n",
      "|other offenses|    126182|\n",
      "|  non-criminal|     92304|\n",
      "|       assault|     76876|\n",
      "| drug/narcotic|     53971|\n",
      "| vehicle theft|     53781|\n",
      "|     vandalism|     44725|\n",
      "|      warrants|     42214|\n",
      "|      burglary|     36755|\n",
      "|suspicious occ|     31414|\n",
      "+--------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      " \n",
      " \n",
      "Total number of unique value of Description: 879\n",
      " \n",
      "Top 10 Crime Description\n",
      "+--------------------+----------+\n",
      "|         Description|totalValue|\n",
      "+--------------------+----------+\n",
      "|grand theft from ...|     60022|\n",
      "|       lost property|     31729|\n",
      "|             battery|     27441|\n",
      "|   stolen automobile|     26897|\n",
      "|drivers license, ...|     26839|\n",
      "|      warrant arrest|     23754|\n",
      "|suspicious occurr...|     21891|\n",
      "|aided case, menta...|     21497|\n",
      "|petty theft from ...|     19771|\n",
      "|malicious mischie...|     17789|\n",
      "+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def top_n_list(df,var, N):\n",
    "    '''\n",
    "    This function determines the top N numbers of the list\n",
    "    '''\n",
    "    print(\"Total number of unique value of\"+' '+var+''+':'+' '+str(df.select(var).distinct().count()))\n",
    "    print(' ')\n",
    "    print('Top'+' '+str(N)+' '+'Crime'+' '+var)\n",
    "    df.groupBy(var).count().withColumnRenamed('count','totalValue')\\\n",
    "    .orderBy(col('totalValue').desc()).show(N)\n",
    "    \n",
    "    \n",
    "top_n_list(data, 'Category',10)\n",
    "print(' ')\n",
    "print(' ')\n",
    "top_n_list(data,'Description',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: __Category feature will be our label (multi-class). How many classes?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select('Category').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __4. Partition the dataset into Training and Test dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 614457\n",
      "Test Dataset Count: 263592\n"
     ]
    }
   ],
   "source": [
    "training, test = data.randomSplit([0.7,0.3], seed=60)\n",
    "#trainingSet.cache()\n",
    "print(\"Training Dataset Count:\", training.count())\n",
    "print(\"Test Dataset Count:\", test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __5. Define Structure to build Pipeline__\n",
    "__The process of cleaning the dataset involves:__  \n",
    "* __Define tokenization function using RegexTokenizer__: RegexTokenizer allows more advanced tokenization based on regular expression (regex) matching. By default, the parameter “pattern” (regex, default: “\\s+”) is used as delimiters to split the input text. Alternatively, users can set parameter “gaps” to false indicating the regex “pattern” denotes “tokens” rather than splitting gaps, and find all matching occurrences as the tokenization result.  \n",
    "\n",
    "* __Define stop remover function using StopWordsRemover__: StopWordsRemover takes as input a sequence of strings (e.g. the output of a Tokenizer) and drops all the stop words from the input sequences. The list of stopwords is specified by the stopWords parameter.  \n",
    "\n",
    "* __Define bag of words function for Descript variable using CountVectorizer__: CountVectorizer can be used as an estimator to extract the vocabulary, and generates a CountVectorizerModel. The model produces sparse representations for the documents over the vocabulary, which can then be passed to other algorithms like LDA. During the fitting process, CountVectorizer will select the top vocabSize words ordered by term frequency across the corpus. An optional parameter minDF also affects the fitting process by specifying the minimum number (or fraction if < 1.0) of documents a term must appear in to be included in the vocabulary.  \n",
    "\n",
    "* __Define function to Encode the values of category variable using StringIndexer__: StringIndexer encodes a string column of labels to a column of label indices. The indices are in (0, numLabels), ordered by label frequencies, so the most frequent label gets index 0. In our case, the label colum(Category) will be encoded to label indices, from 0 to 38; the most frequent label (LARCENY/THEFT) will be indexed as 0.\n",
    "\n",
    "* __Define a pipeline to call these functions__: ML Pipelines provide a uniform set of high-level APIs built on top of DataFrames that help users create and tune practical machine learning pipelines.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, OneHotEncoder, StringIndexer, VectorAssembler, HashingTF, IDF, Word2Vec\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, NaiveBayes \n",
    "\n",
    "#----------------Define tokenizer with regextokenizer()------------------\n",
    "regex_tokenizer = RegexTokenizer(pattern='\\\\W')\\\n",
    "                  .setInputCol(\"Description\")\\\n",
    "                  .setOutputCol(\"tokens\")\n",
    "\n",
    "#----------------Define stopwords with stopwordsremover()---------------------\n",
    "extra_stopwords = ['http','amp','rt','t','c','the']\n",
    "stopwords_remover = StopWordsRemover()\\\n",
    "                    .setInputCol('tokens')\\\n",
    "                    .setOutputCol('filtered_words')\\\n",
    "                    .setStopWords(extra_stopwords)\n",
    "                    \n",
    "\n",
    "#----------Define bags of words using countVectorizer()---------------------------\n",
    "count_vectors = CountVectorizer(vocabSize=10000, minDF=5)\\\n",
    "               .setInputCol(\"filtered_words\")\\\n",
    "               .setOutputCol(\"features\")\n",
    "\n",
    "\n",
    "#-----------Using TF-IDF to vectorise features instead of countVectoriser-----------------\n",
    "hashingTf = HashingTF(numFeatures=10000)\\\n",
    "            .setInputCol(\"filtered_words\")\\\n",
    "            .setOutputCol(\"raw_features\")\n",
    "            \n",
    "#Use minDocFreq to remove sparse terms\n",
    "idf = IDF(minDocFreq=5)\\\n",
    "        .setInputCol(\"raw_features\")\\\n",
    "        .setOutputCol(\"features\")\n",
    "\n",
    "#---------------Define bag of words using Word2Vec---------------------------\n",
    "word2Vec = Word2Vec(vectorSize=1000, minCount=0)\\\n",
    "           .setInputCol(\"filtered_words\")\\\n",
    "           .setOutputCol(\"features\")\n",
    "\n",
    "#-----------Encode the Category variable into label using StringIndexer-----------\n",
    "label_string_idx = StringIndexer()\\\n",
    "                  .setInputCol(\"Category\")\\\n",
    "                  .setOutputCol(\"label\")\n",
    "\n",
    "#-----------Define classifier structure for logistic Regression--------------\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "#---------Define classifier structure for Naive Bayes----------\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "\n",
    "def metrics_ev(labels, metrics):\n",
    "    '''\n",
    "    List of all performance metrics\n",
    "    '''\n",
    "    # Confusion matrix\n",
    "    print(\"---------Confusion matrix-----------------\")\n",
    "    print(metrics.confusionMatrix)\n",
    "    print(' ')    \n",
    "    # Overall statistics\n",
    "    print('----------Overall statistics-----------')\n",
    "    print(\"Precision = %s\" %  metrics.precision())\n",
    "    print(\"Recall = %s\" %  metrics.recall())\n",
    "    print(\"F1 Score = %s\" % metrics.fMeasure())\n",
    "    print(' ')\n",
    "    # Statistics by class\n",
    "    print('----------Statistics by class----------')\n",
    "    for label in sorted(labels):\n",
    "       print(\"Class %s precision = %s\" % (label, metrics.precision(label)))\n",
    "       print(\"Class %s recall = %s\" % (label, metrics.recall(label)))\n",
    "       print(\"Class %s F1 Measure = %s\" % (label, metrics.fMeasure(label, beta=1.0)))\n",
    "    print(' ')\n",
    "    # Weighted stats\n",
    "    print('----------Weighted stats----------------')\n",
    "    print(\"Weighted recall = %s\" % metrics.weightedRecall)\n",
    "    print(\"Weighted precision = %s\" % metrics.weightedPrecision)\n",
    "    print(\"Weighted F(1) Score = %s\" % metrics.weightedFMeasure())\n",
    "    print(\"Weighted F(0.5) Score = %s\" % metrics.weightedFMeasure(beta=0.5))\n",
    "    print(\"Weighted false positive rate = %s\" % metrics.weightedFalsePositiveRate)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __6. Build Multi-Classification__\n",
    "__The stages involve to perform multi-classification include:__\n",
    "1. Model training and evaluation\n",
    "   1. Build baseling model\n",
    "      1. Logistic regression using CountVectorizer features\n",
    "   2. Build secondary models\n",
    "      1. Naive Bayes\n",
    "      2. Logistic regression and Naive Bayes using TF-IDF features\n",
    "      3. Logistic regression and Naive Bayes using word2Vec\n",
    "    \n",
    " ### __(i) Baseline Model__ \n",
    "Baseline model should be quick, low cost and simple to setup and produce a decent results. One of the reason to consider baselines because they iterate very quickly, while wasting minimal time. To further undertand why and how to apply baselines, please refer to Emmanuel Ameisen's article: [Always start with a stupid model, no exceptions.](https://blog.insightdatascience.com/always-start-with-a-stupid-model-no-exceptions-3a22314b9aaa)\n",
    "\n",
    "#### __(a). Apply Logistic Regression with  Count Vector Features__\n",
    "We will build a model to make predictions and score on the test sets using logistics regression using the dataset we transformed using count vectors. And we will see the top 10 predictions from the highest probability from our model, accuracy and other metrics to evaluate our model.  \n",
    "\n",
    "Note: Fit regex_tokenizer,stopwords_remover,count_vectors,label_string_idx, and lr functions into pipeline.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cv_lr = Pipeline().setStages([regex_tokenizer,stopwords_remover,count_vectors,label_string_idx, lr])\n",
    "model_cv_lr = pipeline_cv_lr.fit(training)\n",
    "predictions_cv_lr = model_cv_lr.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------Check Top 5 predictions----------------------------------\n",
      " \n",
      "+------------------------------+-------------+------------------------------+-----+----------+\n",
      "|                   Description|     Category|                   probability|label|prediction|\n",
      "+------------------------------+-------------+------------------------------+-----+----------+\n",
      "|theft, bicycle, <$50, no se...|larceny/theft|[0.8734118515901758,0.02111...|  0.0|       0.0|\n",
      "|theft, bicycle, <$50, no se...|larceny/theft|[0.8734118515901758,0.02111...|  0.0|       0.0|\n",
      "|theft, bicycle, <$50, no se...|larceny/theft|[0.8734118515901758,0.02111...|  0.0|       0.0|\n",
      "|theft, bicycle, <$50, no se...|larceny/theft|[0.8734118515901758,0.02111...|  0.0|       0.0|\n",
      "|theft, bicycle, <$50, no se...|larceny/theft|[0.8734118515901758,0.02111...|  0.0|       0.0|\n",
      "+------------------------------+-------------+------------------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------Check Top 5 predictions----------------------------------')\n",
    "print(' ')\n",
    "predictions_cv_lr.select('Description','Category',\"probability\",\"label\",\"prediction\")\\\n",
    "                                        .orderBy(\"probability\", ascending=False)\\\n",
    "                                        .show(n=5, truncate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "------------------------------Accuracy----------------------------------\n",
      " \n",
      "                       accuracy:0.9724053955014298:\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator \n",
    "evaluator_cv_lr = MulticlassClassificationEvaluator().setPredictionCol(\"prediction\").evaluate(predictions_cv_lr)\n",
    "print(' ')\n",
    "print('------------------------------Accuracy----------------------------------')\n",
    "print(' ')\n",
    "print('                       accuracy:{}:'.format(evaluator_cv_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### __(ii). Secondary Models__\n",
    " #### __(a). Apply Naive Bayes with Count Vector Features__\n",
    "Naive Bayes classifiers are a family of simple probabilistic classifiers based on applying Bayes’ theorem with strong (naive) independence assumptions between the features. The spark.ml implementation currently supports both multinomial naive Bayes and Bernoulli naive Bayes.   \n",
    "\n",
    " Fit regex_tokenizer,stopwords_remover,count_vectors,label_string_idx, and nb functions into pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Secondary model using NaiveBayes\n",
    "pipeline_cv_nb = Pipeline().setStages([regex_tokenizer,stopwords_remover,count_vectors,label_string_idx, nb])\n",
    "model_cv_nb = pipeline_cv_nb.fit(training)\n",
    "predictions_cv_nb = model_cv_nb.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------Accuracy-----------------------------\n",
      " \n",
      "                      accuracy:0.9935325400900984:\n"
     ]
    }
   ],
   "source": [
    "evaluator_cv_nb = MulticlassClassificationEvaluator().setPredictionCol(\"prediction\").evaluate(predictions_cv_nb)\n",
    "print(' ')\n",
    "print('--------------------------Accuracy-----------------------------')\n",
    "print(' ')\n",
    "print('                      accuracy:{}:'.format(evaluator_cv_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __(b). Apply Logistic Regression Using TF-IDF Features__ \n",
    "Term frequency-inverse document frequency (TF-IDF) is a feature vectorization method widely used in text mining to reflect the importance of a term to a document in the corpus. Denote a term by t, a document by _d_, and the corpus by _D_. Term frequency TF(t,d) is the number of times that term t appears in document _d_, while document frequency _DF(t,D)_ is the number of documents that contains term _t_. If we only use term frequency to measure the importance, it is very easy to over-emphasize terms that appear very often but carry little information about the document, e.g. “a”, “the”, and “of”. If a term appears very often across the corpus, it means it doesn’t carry special information about a particular document. Inverse document frequency is a numerical measure of how much information a term provides:   $$IDF(t,D) = log {|D|+1DF \\over (t,D)+1} $$, where |D| is the total number of documents in the corpus. Since logarithm is used, if a term appears in all documents, its IDF value becomes 0. Note that a smoothing term is applied to avoid dividing by zero for terms outside the corpus. The TF-IDF measure is simply the product of TF and IDF:\n",
    "$$TFIDF(t,d,D) = {TF(t,d)⋅IDF(t,D)} $$.  \n",
    "\n",
    "There are several variants on the definition of term frequency and document frequency. In MLlib, we separate TF and IDF to make them flexible.  \n",
    "\n",
    "Note: Fit regex_tokenizer, stopwords_remover,hashingTF, idf,label_string_idx, and nb functions into pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_idf_lr = Pipeline().setStages([regex_tokenizer,stopwords_remover,hashingTf, idf, label_string_idx, lr])\n",
    "model_idf_lr = pipeline_idf_lr.fit(training)\n",
    "predictions_idf_lr = model_idf_lr.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------Check Top 5 predictions----------------------------------\n",
      " \n",
      "+------------------------------+-------------+------------------------------+-----+----------+\n",
      "|                   Description|     Category|                   probability|label|prediction|\n",
      "+------------------------------+-------------+------------------------------+-----+----------+\n",
      "|theft, bicycle, <$50, no se...|larceny/theft|[0.8849102611598371,0.01942...|  0.0|       0.0|\n",
      "|theft, bicycle, <$50, no se...|larceny/theft|[0.8849102611598371,0.01942...|  0.0|       0.0|\n",
      "|theft, bicycle, <$50, no se...|larceny/theft|[0.8849102611598371,0.01942...|  0.0|       0.0|\n",
      "|theft, bicycle, <$50, no se...|larceny/theft|[0.8849102611598371,0.01942...|  0.0|       0.0|\n",
      "|theft, bicycle, <$50, no se...|larceny/theft|[0.8849102611598371,0.01942...|  0.0|       0.0|\n",
      "+------------------------------+-------------+------------------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------Check Top 5 predictions----------------------------------')\n",
    "print(' ')\n",
    "predictions_idf_lr.select('Description','Category',\"probability\",\"label\",\"prediction\")\\\n",
    "                                        .orderBy(\"probability\", ascending=False)\\\n",
    "                                        .show(n=5, truncate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "-------------------------------Accuracy---------------------------------\n",
      " \n",
      "                        accuracy:0.9722900528485308:\n"
     ]
    }
   ],
   "source": [
    "evaluator_idf_lr = MulticlassClassificationEvaluator().setPredictionCol(\"prediction\").evaluate(predictions_idf_lr)\n",
    "print(' ')\n",
    "print('-------------------------------Accuracy---------------------------------')\n",
    "print(' ')\n",
    "print('                        accuracy:{}:'.format(evaluator_idf_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __(c). Apply Naive Bayes with TF-IDF Features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_idf_nb = Pipeline().setStages([regex_tokenizer,stopwords_remover,hashingTf, idf, label_string_idx, nb])\n",
    "model_idf_nb = pipeline_idf_nb.fit(training)\n",
    "predictions_idf_nb = model_idf_nb.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "-----------------------------Accuracy-----------------------------\n",
      " \n",
      "                          accuracy:0.9949302190940209:\n"
     ]
    }
   ],
   "source": [
    "evaluator_idf_nb = MulticlassClassificationEvaluator().setPredictionCol(\"prediction\").evaluate(predictions_idf_nb)\n",
    "print(' ')\n",
    "print('-----------------------------Accuracy-----------------------------')\n",
    "print(' ')\n",
    "print('                          accuracy:{}:'.format(evaluator_idf_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __(e). Apply Logistic Regression Using Word2Vec features__ \n",
    "Word2Vec is an Estimator which takes sequences of words representing documents and trains a Word2VecModel. The model maps each word to a unique fixed-size vector. The Word2VecModel transforms each document into a vector using the average of all words in the document; this vector can then be used as features for prediction, document similarity calculations, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/t0m/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1207, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/t0m/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1033, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/t0m/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1211, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o85.getParam",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-347233ed1b41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpipeline_wv_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetStages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mregex_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstopwords_remover\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_string_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_wv_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_wv_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictions_wv_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_wv_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transfer_params_to_java\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasDefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0mpair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_java_param_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_defaultParamMap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0mpair_defaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_defaults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_make_java_param_pair\u001b[0;34m(self, param, value)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolveParam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mjava_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetParam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0mjava_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    332\u001b[0m                     format(target_id, \".\", name, value))\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             raise Py4JError(\n\u001b[0m\u001b[1;32m    335\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                 format(target_id, \".\", name))\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o85.getParam"
     ]
    }
   ],
   "source": [
    "pipeline_wv_lr = Pipeline().setStages([regex_tokenizer,stopwords_remover, word2Vec, label_string_idx, lr])\n",
    "model_wv_lr = pipeline_wv_lr.fit(training)\n",
    "predictions_wv_lr = model_wv_lr.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/t0m/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1207, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/t0m/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1033, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/t0m/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1211, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "org does not exist in the JVM",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-639fc79eaeb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluator_wv_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetPredictionCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_wv_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--------------------------Accuracy------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'                  accuracy:{}:'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluator_wv_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, predictionCol, labelCol, metricName, weightCol, metricLabel, beta, probabilityCol, eps)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[1;32m    466\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         self._java_obj = self._new_java_obj(\n\u001b[0m\u001b[1;32m    468\u001b[0m             \"org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\", self.uid)\n\u001b[1;32m    469\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setDefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetricName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetricLabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjava_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1703\u001b[0m             message = compute_exception_message(\n\u001b[1;32m   1704\u001b[0m                 \"{0} does not exist in the JVM\".format(name), error_message)\n\u001b[0;32m-> 1705\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: org does not exist in the JVM"
     ]
    }
   ],
   "source": [
    "evaluator_wv_lr = MulticlassClassificationEvaluator().setPredictionCol(\"prediction\").evaluate(predictions_wv_lr)\n",
    "print('--------------------------Accuracy------------')\n",
    "print(' ')\n",
    "print('                  accuracy:{}:'.format(evaluator_wv_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __(f). Apply Naive Bayes Using Word2Vec features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:37337)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/t0m/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/t0m/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:37337)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c5d6779556df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpipeline_wv_nb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetStages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mregex_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstopwords_remover\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_string_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_wv_nb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_wv_nb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictions_wv_nb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_wv_nb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transfer_params_to_java\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasDefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0mpair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_java_param_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_defaultParamMap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0mpair_defaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_defaults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_make_java_param_pair\u001b[0;34m(self, param, value)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolveParam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mjava_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetParam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0mjava_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1029\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \"\"\"\n\u001b[0;32m-> 1031\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    983\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    984\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 985\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1125\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_authenticate_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:37337)"
     ]
    }
   ],
   "source": [
    "pipeline_wv_nb = Pipeline().setStages([regex_tokenizer,stopwords_remover, word2Vec, label_string_idx, nb])\n",
    "model_wv_nb = pipeline_wv_nb.fit(training)\n",
    "predictions_wv_nb = model_wv_nb.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:37337)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/t0m/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/t0m/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:37337)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ab2a2d9d7e41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluator_wv_nb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetPredictionCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_wv_nb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--------Accuracy------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy:{}%:'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluator_wv_nb\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, predictionCol, labelCol, metricName, weightCol, metricLabel, beta, probabilityCol, eps)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[1;32m    466\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         self._java_obj = self._new_java_obj(\n\u001b[0m\u001b[1;32m    468\u001b[0m             \"org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\", self.uid)\n\u001b[1;32m    469\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setDefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetricName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetricLabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjava_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mUserHelpAutoCompletion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         answer = self._gateway_client.send_command(\n\u001b[0m\u001b[1;32m   1693\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFLECTION_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1029\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \"\"\"\n\u001b[0;32m-> 1031\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    983\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    984\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 985\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1125\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_authenticate_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:37337)"
     ]
    }
   ],
   "source": [
    "evaluator_wv_nb = MulticlassClassificationEvaluator().setPredictionCol(\"prediction\").evaluate(predictions_wv_nb)\n",
    "print('--------Accuracy------------')\n",
    "print(' ')\n",
    "print('accuracy:{}%:'.format(round(evaluator_wv_nb *100),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. __Results:__\n",
    "__The table below has accuracy of the models generated by different extraction techniques.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                    | Logistic Regression | Naive Bayes |\n",
    "| -------------------|:-------------------:|------------:|\n",
    "| Count Vectoriser   |  97.2%              |   99.3%     |\n",
    "| TF-IDF             |  97.2%              |   99.5%     |\n",
    "| Word2Vec           |  90.7%              |             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: __As you can see, TF-IDF proves to be best vectoriser for this dataset, while Naive Bayes proves to be better algorithm for text analysis than Logistic regression.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __8. Deploy the Model__\n",
    "We will use Flask. To know more about Flask, check [Full Stack Python.](https://www.fullstackpython.com/flask.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image('flask.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask, request, jsonify\n",
    "# from pyspark.ml import PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the Model\n",
    "# MODEL=pyspark.ml.PipelineModel(\"spark-naive-bayes-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTTP_BAD_REQUEST = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route('/predict')\n",
    "# def predict():\n",
    "#     Description = request.args.get('Description', default=None, type=str)\n",
    "    \n",
    "#     # Reject request that have bad or missing values.\n",
    "#     if Description is None:\n",
    "#         # Provide the caller with feedback on why the record is unscorable.\n",
    "#         message = ('Record cannot be scored because of '\n",
    "#                    'missing or unacceptable values. '\n",
    "#                    'All values must be present and of type string.')\n",
    "#         response = jsonify(status='error',\n",
    "#                            error_message=message)\n",
    "#         # Sets the status code to 400\n",
    "#         response.status_code = HTTP_BAD_REQUEST\n",
    "#         return response\n",
    "    \n",
    "#     features = [[Description]]\n",
    "#     predictions = MODEL.transform(features)\n",
    "#     label_pred = predictions.select(\"Description\",\"Category\",\"probability\",\"prediction\")\n",
    "#     return jsonify(status='complete', label=label_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     app.run(debug=True,port=4444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\"\\n  \"http://www.w3.org/TR/html4/loose.dtd\">\\n<html>\\n  <head>\\n    <title>AttributeError: &#x27;str&#x27; object has no attribute &#x27;transform&#x27; // Werkzeug Debugger</title>\\n    <link rel=\"stylesheet\" href=\"?__debugger__=yes&amp;cmd=resource&amp;f=style.css\"\\n        type=\"text/css\">\\n    <!-- We need to make sure this has a favicon so that the debugger does\\n         not accidentally trigger a request to /favicon.ico which might\\n         change the application\\'s state. -->\\n    <link rel=\"shortcut icon\"\\n        href=\"?__debugger__=yes&amp;cmd=resource&amp;f=console.png\">\\n    <script src=\"?__debugger__=yes&amp;cmd=resource&amp;f=debugger.js\"></script>\\n    <script type=\"text/javascript\">\\n      var TRACEBACK = 140545752074848,\\n          CONSOLE_MODE = false,\\n          EVALEX = true,\\n          EVALEX_TRUSTED = false,\\n          SECRET = \"gsuru4sNuWhbdJmS4k2o\";\\n    </script>\\n  </head>\\n  <body style=\"background-color: #fff\">\\n    <div class=\"debugger\">\\n<h1>AttributeError</h1>\\n<div class=\"detail\">\\n  <p class=\"errormsg\">AttributeError: &#x27;str&#x27; object has no attribute &#x27;transform&#x27;</p>\\n</div>\\n<h2 class=\"traceback\">Traceback <em>(most recent call last)</em></h2>\\n<div class=\"traceback\">\\n  <h3></h3>\\n  <ul><li><div class=\"frame\" id=\"frame-140545752075088\">\\n  <h4>File <cite class=\"filename\">\"/home/t0m/.local/lib/python3.8/site-packages/flask/app.py\"</cite>,\\n      line <em class=\"line\">2088</em>,\\n      in <code class=\"function\">__call__</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">    </span>def __call__(self, environ: dict, start_response: t.Callable) -&gt; t.Any:</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>&quot;&quot;&quot;The WSGI server calls the Flask application object as the</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>WSGI application. This calls :meth:`wsgi_app`, which can be</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>wrapped to apply middleware.</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>&quot;&quot;&quot;</pre>\\n<pre class=\"line current\"><span class=\"ws\">        </span>return self.wsgi_app(environ, start_response)</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-140545752075232\">\\n  <h4>File <cite class=\"filename\">\"/home/t0m/.local/lib/python3.8/site-packages/flask/app.py\"</cite>,\\n      line <em class=\"line\">2073</em>,\\n      in <code class=\"function\">wsgi_app</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">            </span>try:</pre>\\n<pre class=\"line before\"><span class=\"ws\">                </span>ctx.push()</pre>\\n<pre class=\"line before\"><span class=\"ws\">                </span>response = self.full_dispatch_request()</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>except Exception as e:</pre>\\n<pre class=\"line before\"><span class=\"ws\">                </span>error = e</pre>\\n<pre class=\"line current\"><span class=\"ws\">                </span>response = self.handle_exception(e)</pre>\\n<pre class=\"line after\"><span class=\"ws\">            </span>except:  # noqa: B001</pre>\\n<pre class=\"line after\"><span class=\"ws\">                </span>error = sys.exc_info()[1]</pre>\\n<pre class=\"line after\"><span class=\"ws\">                </span>raise</pre>\\n<pre class=\"line after\"><span class=\"ws\">            </span>return response(environ, start_response)</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>finally:</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-140545752073696\">\\n  <h4>File <cite class=\"filename\">\"/home/t0m/.local/lib/python3.8/site-packages/flask/app.py\"</cite>,\\n      line <em class=\"line\">2070</em>,\\n      in <code class=\"function\">wsgi_app</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">        </span>ctx = self.request_context(environ)</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>error: t.Optional[BaseException] = None</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>try:</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>try:</pre>\\n<pre class=\"line before\"><span class=\"ws\">                </span>ctx.push()</pre>\\n<pre class=\"line current\"><span class=\"ws\">                </span>response = self.full_dispatch_request()</pre>\\n<pre class=\"line after\"><span class=\"ws\">            </span>except Exception as e:</pre>\\n<pre class=\"line after\"><span class=\"ws\">                </span>error = e</pre>\\n<pre class=\"line after\"><span class=\"ws\">                </span>response = self.handle_exception(e)</pre>\\n<pre class=\"line after\"><span class=\"ws\">            </span>except:  # noqa: B001</pre>\\n<pre class=\"line after\"><span class=\"ws\">                </span>error = sys.exc_info()[1]</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-140545752075520\">\\n  <h4>File <cite class=\"filename\">\"/home/t0m/.local/lib/python3.8/site-packages/flask/app.py\"</cite>,\\n      line <em class=\"line\">1515</em>,\\n      in <code class=\"function\">full_dispatch_request</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">            </span>request_started.send(self)</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>rv = self.preprocess_request()</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>if rv is None:</pre>\\n<pre class=\"line before\"><span class=\"ws\">                </span>rv = self.dispatch_request()</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>except Exception as e:</pre>\\n<pre class=\"line current\"><span class=\"ws\">            </span>rv = self.handle_user_exception(e)</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>return self.finalize_request(rv)</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\">    </span>def finalize_request(</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>self,</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>rv: t.Union[ResponseReturnValue, HTTPException],</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-140545752075568\">\\n  <h4>File <cite class=\"filename\">\"/home/t0m/.local/lib/python3.8/site-packages/flask/app.py\"</cite>,\\n      line <em class=\"line\">1513</em>,\\n      in <code class=\"function\">full_dispatch_request</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">        </span>self.try_trigger_before_first_request_functions()</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>try:</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>request_started.send(self)</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>rv = self.preprocess_request()</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>if rv is None:</pre>\\n<pre class=\"line current\"><span class=\"ws\">                </span>rv = self.dispatch_request()</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>except Exception as e:</pre>\\n<pre class=\"line after\"><span class=\"ws\">            </span>rv = self.handle_user_exception(e)</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>return self.finalize_request(rv)</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\">    </span>def finalize_request(</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-140545752075616\">\\n  <h4>File <cite class=\"filename\">\"/home/t0m/.local/lib/python3.8/site-packages/flask/app.py\"</cite>,\\n      line <em class=\"line\">1499</em>,\\n      in <code class=\"function\">dispatch_request</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">            </span>getattr(rule, &quot;provide_automatic_options&quot;, False)</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>and req.method == &quot;OPTIONS&quot;</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>):</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>return self.make_default_options_response()</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span># otherwise dispatch to the handler for that endpoint</pre>\\n<pre class=\"line current\"><span class=\"ws\">        </span>return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\">    </span>def full_dispatch_request(self) -&gt; Response:</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>&quot;&quot;&quot;Dispatches the request and on top of that performs request</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>pre and postprocessing as well as HTTP exception catching and</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>error handling.</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-140545752075664\">\\n  <h4>File <cite class=\"filename\">\"/tmp/netcom_dataScience_dataAnalytics/Day5/demo/serve-me.py\"</cite>,\\n      line <em class=\"line\">28</em>,\\n      in <code class=\"function\">predict</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">        </span># Sets the status code to 400</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>response.status_code = HTTP_BAD_REQUEST</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>return response</pre>\\n<pre class=\"line before\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line before\"><span class=\"ws\">    </span>features = [[Description]]</pre>\\n<pre class=\"line current\"><span class=\"ws\">    </span>predictions = MODEL.transform(features)</pre>\\n<pre class=\"line after\"><span class=\"ws\">    </span>label_pred = predictions.select(&quot;Description&quot;,&quot;Category&quot;,&quot;probability&quot;,&quot;prediction&quot;)</pre>\\n<pre class=\"line after\"><span class=\"ws\">    </span>return jsonify(status=&#x27;complete&#x27;, label=label_pred)</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\"></span>if __name__ == &#x27;__main__&#x27;:</pre>\\n<pre class=\"line after\"><span class=\"ws\">    </span>app.run(debug=True,port=4444)</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-140545752075328\">\\n  <h4>File <cite class=\"filename\">\"/home/t0m/.local/lib/python3.8/site-packages/pyspark/ml/base.py\"</cite>,\\n      line <em class=\"line\">217</em>,\\n      in <code class=\"function\">transform</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">            </span>params = dict()</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>if isinstance(params, dict):</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>if params:</pre>\\n<pre class=\"line before\"><span class=\"ws\">                </span>return self.copy(params)._transform(dataset)</pre>\\n<pre class=\"line before\"><span class=\"ws\">            </span>else:</pre>\\n<pre class=\"line current\"><span class=\"ws\">                </span>return self._transform(dataset)</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>else:</pre>\\n<pre class=\"line after\"><span class=\"ws\">            </span>raise ValueError(&quot;Params must be a param map but got %s.&quot; % type(params))</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\"></span>@inherit_doc</pre></div>\\n</div>\\n\\n<li><div class=\"frame\" id=\"frame-140545752075472\">\\n  <h4>File <cite class=\"filename\">\"/home/t0m/.local/lib/python3.8/site-packages/pyspark/ml/pipeline.py\"</cite>,\\n      line <em class=\"line\">278</em>,\\n      in <code class=\"function\">_transform</code></h4>\\n  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">        </span>super(PipelineModel, self).__init__()</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>self.stages = stages</pre>\\n<pre class=\"line before\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line before\"><span class=\"ws\">    </span>def _transform(self, dataset):</pre>\\n<pre class=\"line before\"><span class=\"ws\">        </span>for t in self.stages:</pre>\\n<pre class=\"line current\"><span class=\"ws\">            </span>dataset = t.transform(dataset)</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>return dataset</pre>\\n<pre class=\"line after\"><span class=\"ws\"></span> </pre>\\n<pre class=\"line after\"><span class=\"ws\">    </span>def copy(self, extra=None):</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>&quot;&quot;&quot;</pre>\\n<pre class=\"line after\"><span class=\"ws\">        </span>Creates a copy of this instance.</pre></div>\\n</div>\\n</ul>\\n  <blockquote>AttributeError: &#x27;str&#x27; object has no attribute &#x27;transform&#x27;</blockquote>\\n</div>\\n\\n<div class=\"plain\">\\n    <p>\\n      This is the Copy/Paste friendly version of the traceback.\\n    </p>\\n    <textarea cols=\"50\" rows=\"10\" name=\"code\" readonly>Traceback (most recent call last):\\n  File &quot;/home/t0m/.local/lib/python3.8/site-packages/flask/app.py&quot;, line 2088, in __call__\\n    return self.wsgi_app(environ, start_response)\\n  File &quot;/home/t0m/.local/lib/python3.8/site-packages/flask/app.py&quot;, line 2073, in wsgi_app\\n    response = self.handle_exception(e)\\n  File &quot;/home/t0m/.local/lib/python3.8/site-packages/flask/app.py&quot;, line 2070, in wsgi_app\\n    response = self.full_dispatch_request()\\n  File &quot;/home/t0m/.local/lib/python3.8/site-packages/flask/app.py&quot;, line 1515, in full_dispatch_request\\n    rv = self.handle_user_exception(e)\\n  File &quot;/home/t0m/.local/lib/python3.8/site-packages/flask/app.py&quot;, line 1513, in full_dispatch_request\\n    rv = self.dispatch_request()\\n  File &quot;/home/t0m/.local/lib/python3.8/site-packages/flask/app.py&quot;, line 1499, in dispatch_request\\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\\n  File &quot;/tmp/netcom_dataScience_dataAnalytics/Day5/demo/serve-me.py&quot;, line 28, in predict\\n    predictions = MODEL.transform(features)\\n  File &quot;/home/t0m/.local/lib/python3.8/site-packages/pyspark/ml/base.py&quot;, line 217, in transform\\n    return self._transform(dataset)\\n  File &quot;/home/t0m/.local/lib/python3.8/site-packages/pyspark/ml/pipeline.py&quot;, line 278, in _transform\\n    dataset = t.transform(dataset)\\nAttributeError: &#x27;str&#x27; object has no attribute &#x27;transform&#x27;</textarea>\\n</div>\\n<div class=\"explanation\">\\n  The debugger caught an exception in your WSGI application.  You can now\\n  look at the traceback which led to the error.  <span class=\"nojavascript\">\\n  If you enable JavaScript you can also use additional features such as code\\n  execution (if the evalex feature is enabled), automatic pasting of the\\n  exceptions and much more.</span>\\n</div>\\n      <div class=\"footer\">\\n        Brought to you by <strong class=\"arthur\">DON\\'T PANIC</strong>, your\\n        friendly Werkzeug powered traceback interpreter.\\n      </div>\\n    </div>\\n\\n    <div class=\"pin-prompt\">\\n      <div class=\"inner\">\\n        <h3>Console Locked</h3>\\n        <p>\\n          The console is locked and needs to be unlocked by entering the PIN.\\n          You can find the PIN printed out on the standard output of your\\n          shell that runs the server.\\n        <form>\\n          <p>PIN:\\n            <input type=text name=pin size=14>\\n            <input type=submit name=btn value=\"Confirm Pin\">\\n        </form>\\n      </div>\\n    </div>\\n  </body>\\n</html>\\n\\n<!--\\n\\nTraceback (most recent call last):\\n  File \"/home/t0m/.local/lib/python3.8/site-packages/flask/app.py\", line 2088, in __call__\\n    return self.wsgi_app(environ, start_response)\\n  File \"/home/t0m/.local/lib/python3.8/site-packages/flask/app.py\", line 2073, in wsgi_app\\n    response = self.handle_exception(e)\\n  File \"/home/t0m/.local/lib/python3.8/site-packages/flask/app.py\", line 2070, in wsgi_app\\n    response = self.full_dispatch_request()\\n  File \"/home/t0m/.local/lib/python3.8/site-packages/flask/app.py\", line 1515, in full_dispatch_request\\n    rv = self.handle_user_exception(e)\\n  File \"/home/t0m/.local/lib/python3.8/site-packages/flask/app.py\", line 1513, in full_dispatch_request\\n    rv = self.dispatch_request()\\n  File \"/home/t0m/.local/lib/python3.8/site-packages/flask/app.py\", line 1499, in dispatch_request\\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\\n  File \"/tmp/netcom_dataScience_dataAnalytics/Day5/demo/serve-me.py\", line 28, in predict\\n    predictions = MODEL.transform(features)\\n  File \"/home/t0m/.local/lib/python3.8/site-packages/pyspark/ml/base.py\", line 217, in transform\\n    return self._transform(dataset)\\n  File \"/home/t0m/.local/lib/python3.8/site-packages/pyspark/ml/pipeline.py\", line 278, in _transform\\n    dataset = t.transform(dataset)\\nAttributeError: \\'str\\' object has no attribute \\'transform\\'\\n\\n-->\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.get('http://127.0.0.1:4444/predict?Description=arson')\n",
    "response.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-on-jupyter@1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
