{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis Using Neural Networks\n",
    "----\n",
    "Only process numeric representations of things\n",
    "\n",
    "I can model a sentence or a document as a numeric form; I can use some numeric coding to `X1`; That way I can represent a word as a vector; taking a document in as `tensors` ( n-dimensional thingy )\n",
    "\n",
    "#### Word Embedding:\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "###### _one hot_ large corpus of every word \n",
    "\n",
    "* Large vocabulary will have an enormous amount of features\n",
    "* unordered will lose a lot of context and relationship between the words \n",
    "* Binary; no frequency analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### _frequency based_\n",
    "* Counter Vectors wordcounts\n",
    "* Term-Frequency-Inverse Document Frequency -> how important to doc and corpus as a whole. \n",
    "* Tokenize each word, take teh counts, express the review as counts\n",
    "* Large vocab can be sparse; \n",
    "    * you can choose the _Top-N_ most common words\n",
    "    * You can also hash individual words to buckets; sized so that buckets will make collisions rare ( a word is in the same bucket as another bucket )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TF-IDF Algo\n",
    "-----\n",
    "* How often a word appears in document and the corpus\n",
    "\n",
    "* Tokenize each word as an integer; the document is represented as a tensor\n",
    "* every word is represented as a `score = TermFrequency(wi, dj) * InverseDocumentFrequency(wi, D)`\n",
    "* Frequency in the corpus makes the scor for a word reduces for more common words ( the, an, uhh )\n",
    "* Frequency in the document, assumes that it is important\n",
    "* Encoding every word in the document, and scores it\n",
    "    * Advantages: feature vector is more tractable in size\n",
    "    * Scores capture frequency and relevance\n",
    "    * Context is not captures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "######  _prediction based_ \n",
    "* used by deep learning networks, to look for meaning and semantics of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representing Text in Numerical Form\n",
    "----\n",
    "* `CountVectorizer`\n",
    "* `TfidfVectorizer`\n",
    "* `HashingVectorizer`\n",
    "\n",
    "each implements a `fit()` to pass a corpus in, so the vectorizer learns the dataset\n",
    "\n",
    "`transform()` will assign the generated id to each word in the corpus\n",
    "\n",
    "smaller sets can usually be done with`fit_and_transform`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extracting Features from Text\n",
    "##### Using Bag of Words, TF-IDF Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a corpus of 4 documents with some repeated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['This is the first document.',\n",
    "          'This is the second document.', \n",
    "          'Third document. Document number three', \n",
    "          'Number four. To repeat, number four']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use CountVectorizer to convert a collection of text documents to a \"bag of words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x12 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 18 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "#instantiate\n",
    "bag_of_words = vectorizer.fit_transform(corpus)\n",
    "\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing the bag of words created\n",
    "----\n",
    "you can see that each word is indexed and identified by a number and the document is comes from\n",
    "The same words will have the same number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View what the \"bag\" looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 9)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 9)\t1\n",
      "  (2, 10)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 0)\t2\n",
      "  (3, 5)\t1\n",
      "  (3, 11)\t1\n",
      "  (3, 2)\t2\n",
      "  (3, 4)\t2\n"
     ]
    }
   ],
   "source": [
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the value to which a word is mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.get('document')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access all the words inside \n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 9,\n",
       " 'is': 3,\n",
       " 'the': 7,\n",
       " 'first': 1,\n",
       " 'document': 0,\n",
       " 'second': 6,\n",
       " 'third': 8,\n",
       " 'number': 4,\n",
       " 'three': 10,\n",
       " 'four': 2,\n",
       " 'to': 11,\n",
       " 'repeat': 5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Much easier to view it all as a pandas dataframe\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>four</th>\n",
       "      <th>is</th>\n",
       "      <th>number</th>\n",
       "      <th>repeat</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "      <th>three</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document  first  four  is  number  repeat  second  the  third  this  three  \\\n",
       "0         1      1     0   1       0       0       0    1      0     1      0   \n",
       "1         1      0     0   1       0       0       1    1      0     1      0   \n",
       "2         2      0     0   0       1       0       0    0      1     0      1   \n",
       "3         0      0     2   0       2       1       0    0      0     0      0   \n",
       "\n",
       "   to  \n",
       "0   0  \n",
       "1   0  \n",
       "2   0  \n",
       "3   1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bag_of_words.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extend bag of words with TF-IDF weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Everything has a unique id and a score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9)\t0.43584673254990375\n",
      "  (0, 3)\t0.43584673254990375\n",
      "  (0, 7)\t0.43584673254990375\n",
      "  (0, 1)\t0.5528163151092931\n",
      "  (0, 0)\t0.3528554929793508\n",
      "  (1, 9)\t0.43584673254990375\n",
      "  (1, 3)\t0.43584673254990375\n",
      "  (1, 7)\t0.43584673254990375\n",
      "  (1, 0)\t0.3528554929793508\n",
      "  (1, 6)\t0.5528163151092931\n",
      "  (2, 0)\t0.6191395067937654\n",
      "  (2, 8)\t0.4850008395708102\n",
      "  (2, 4)\t0.3823802326982809\n",
      "  (2, 10)\t0.4850008395708102\n",
      "  (3, 4)\t0.5412799489419371\n",
      "  (3, 2)\t0.6865449812276998\n",
      "  (3, 11)\t0.3432724906138499\n",
      "  (3, 5)\t0.3432724906138499\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "bag_of_words = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.get('document')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Represent as a dataframe\n",
    "---- \n",
    "contain scores not frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>four</th>\n",
       "      <th>is</th>\n",
       "      <th>number</th>\n",
       "      <th>repeat</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "      <th>three</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.352855</td>\n",
       "      <td>0.552816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.352855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552816</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.619140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.38238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.686545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.54128</td>\n",
       "      <td>0.343272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document     first      four        is   number    repeat    second  \\\n",
       "0  0.352855  0.552816  0.000000  0.435847  0.00000  0.000000  0.000000   \n",
       "1  0.352855  0.000000  0.000000  0.435847  0.00000  0.000000  0.552816   \n",
       "2  0.619140  0.000000  0.000000  0.000000  0.38238  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.686545  0.000000  0.54128  0.343272  0.000000   \n",
       "\n",
       "        the     third      this     three        to  \n",
       "0  0.435847  0.000000  0.435847  0.000000  0.000000  \n",
       "1  0.435847  0.000000  0.435847  0.000000  0.000000  \n",
       "2  0.000000  0.485001  0.000000  0.485001  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.343272  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bag_of_words.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View all the words and their corresponding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 9,\n",
       " 'is': 3,\n",
       " 'the': 7,\n",
       " 'first': 1,\n",
       " 'document': 0,\n",
       " 'second': 6,\n",
       " 'third': 8,\n",
       " 'number': 4,\n",
       " 'three': 10,\n",
       " 'four': 2,\n",
       " 'to': 11,\n",
       " 'repeat': 5}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Really Big Things\n",
    "----\n",
    "Hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Hashing Vectorizer\n",
    "* One issue with CountVectorizer and TF-IDF Vectorizer is that the number of features can get very large if the vocabulary is very large\n",
    "* The whole vocabulary will be stored in memory, and this may end up taking a lot of space\n",
    "* With Hashing Vectorizer, one can limit the number of features, let's say to a number <b>n</b>\n",
    "* Each word will be hashed to one of the n values\n",
    "* There will collisions where different words will be hashed to the same value\n",
    "* In many instances, peformance does not really suffer in spite of the collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t-0.8944271909999159\n",
      "  (0, 5)\t0.4472135954999579\n",
      "  (0, 6)\t0.0\n",
      "  (1, 0)\t-0.5773502691896258\n",
      "  (1, 3)\t0.5773502691896258\n",
      "  (1, 5)\t0.5773502691896258\n",
      "  (1, 6)\t0.0\n",
      "  (2, 0)\t-0.7559289460184544\n",
      "  (2, 3)\t0.3779644730092272\n",
      "  (2, 5)\t0.3779644730092272\n",
      "  (2, 7)\t0.3779644730092272\n",
      "  (3, 0)\t0.31622776601683794\n",
      "  (3, 3)\t0.31622776601683794\n",
      "  (3, 5)\t0.6324555320336759\n",
      "  (3, 7)\t0.6324555320336759\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "# set the number of buckets=8\n",
    "vectorizer = HashingVectorizer(n_features=8)\n",
    "feature_vector = vectorizer.fit_transform(corpus)\n",
    "print(feature_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There is no way to compute the inverse transform to get the words from the hashed value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
